exporters:
  otlphttp:
    endpoint: ${env:KM_COLLECTOR_ENDPOINT}
    headers:
      Authorization: ${env:KM_API_KEY}
extensions:
  health_check:
    endpoint: 0.0.0.0:13133
processors:
  attributes/metrics:
    actions:
      - key: cluster
        value: ${env:KM_CLUSTER_NAME}
        action: insert
  batch:
    send_batch_size: 10000
    timeout: 10s
  k8sattributes:
    auth_type: serviceAccount
    extract:
      annotations:
        - from: pod
          key: instrumentation.kloudmate.com
          tag_name: instrumentation.kloudmate.com
        - from: namespace
          key: instrumentation.kloudmate.com
          tag_name: instrumentation.kloudmate.com
        - from: node
          key: instrumentation.kloudmate.com
          tag_name: instrumentation.kloudmate.com
      metadata:
        - k8s.pod.name
        - k8s.pod.uid
        - k8s.deployment.name
        - k8s.namespace.name
        - k8s.node.name
        - k8s.pod.start_time
        - k8s.statefulset.uid
        - k8s.replicaset.uid
        - k8s.daemonset.uid
        - k8s.deployment.uid
        - k8s.job.uid
        - k8s.pod.ip
        - k8s.daemonset.name
        - k8s.statefulset.name
        - k8s.replicaset.name
        - k8s.cronjob.name
        - k8s.job.name
    passthrough: false
    pod_association:
      - sources:
          - from: resource_attribute
            name: k8s.pod.uid
  resource:
    attributes:
      - action: upsert
        from_attribute: host.name
        key: host.id
      - action: insert
        from_attribute: k8s.node.uid
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.namespace.uid
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.pod.uid
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.container.name
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.replicaset.uid
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.statefulset.uid
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.cronjob.uid
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.job.uid
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.daemonset.uid
        key: k8s.cluster.name
      - action: insert
        from_attribute: k8s.deployment.uid
        key: k8s.cluster.name
      - action: upsert
        key: km.agent.version
        value: ${env:KM_AGENT_VERSION}
  resource/cluster:
    attributes:
      - action: upsert
        key: k8s.cluster.name
        value: ${env:KM_CLUSTER_NAME}
      - action: update
        from_attribute: k8s.node.name
        key: host.id
      - action: update
        from_attribute: k8s.node.name
        key: host.name
  resource/k8s_events:
    attributes:
      - action: upsert
        key: service.name
        value: k8s-events
  resource/k8s_objects:
    attributes:
      - action: upsert
        key: service.name
        value: k8s-objects
  transform/loglevels:
    log_statements:
      - context: log
        error_mode: ignore
        statements:
          # JSON parsing: Extends log attributes with the fields from structured log body content, either as an OTEL map or
          # as a string containing JSON content.
          - set(log.cache, ExtractPatterns(log.body, "(?P<0>(\\{.*\\}))")) where
            IsString(log.body)
          - merge_maps(log.attributes, ParseJSON(log.cache["0"]), "upsert")
            where IsMap(log.cache)
          - flatten(log.attributes) where IsMap(log.cache)
          - merge_maps(log.attributes, log.body, "upsert") where IsMap(log.body)
      - context: log
        error_mode: ignore
        conditions:
          - severity_number == 0 and severity_text == ""
        statements:
          # Infer: extract the first log level keyword from the first 256 characters of the body
          - set(log.cache["substr"], log.body.string) where Len(log.body.string)
            < 256
          - set(log.cache["substr"], Substring(log.body.string, 0, 256)) where
            Len(log.body.string) >= 256
          - set(log.cache, ExtractPatterns(log.cache["substr"],
            "(?i)(?P<0>(alert|crit|emerg|fatal|error|err|warn|notice|debug|dbug|trace))"))
          # Infer: detect FATAL
          - set(log.severity_number, SEVERITY_NUMBER_FATAL) where
            IsMatch(log.cache["0"], "(?i)(alert|crit|emerg|fatal)")
          - set(log.severity_text, "fatal") where log.severity_number ==
            SEVERITY_NUMBER_FATAL
          # Infer: detect ERROR
          - set(log.severity_number, SEVERITY_NUMBER_ERROR) where
            IsMatch(log.cache["0"], "(?i)(error|err)")
          - set(log.severity_text, "error") where log.severity_number ==
            SEVERITY_NUMBER_ERROR
          # Infer: detect WARN
          - set(log.severity_number, SEVERITY_NUMBER_WARN) where
            IsMatch(log.cache["0"], "(?i)(warn|notice)")
          - set(log.severity_text, "warn") where log.severity_number ==
            SEVERITY_NUMBER_WARN
          # Infer: detect DEBUG
          - set(log.severity_number, SEVERITY_NUMBER_DEBUG) where
            IsMatch(log.cache["0"], "(?i)(debug|dbug)")
          - set(log.severity_text, "debug") where log.severity_number ==
            SEVERITY_NUMBER_DEBUG
          # Infer: detect TRACE
          - set(log.severity_number, SEVERITY_NUMBER_TRACE) where
            IsMatch(log.cache["0"], "(?i)(trace)")
          - set(log.severity_text, "trace") where log.severity_number ==
            SEVERITY_NUMBER_TRACE
          # Infer: else
          - set(log.severity_text, "info") where log.severity_number == 0
          - set(log.severity_number, SEVERITY_NUMBER_INFO) where log.severity_number == 0
      - context: log
        error_mode: ignore
        statements:
          # Normalize the severity_text case
          - set(log.severity_text, ConvertCase(log.severity_text, "lower"))
  transform/add_labels:
    log_statements:
      - context: log
        statements: []
  transform/copyservicefromlogattributes:
    error_mode: ignore
    log_statements:
      - context: log
        statements:
          - set(resource.attributes["service.name"], log.attributes["service.name"]) where
            log.attributes["service.name"] != nil and resource.attributes["service.name"]
            == nil
receivers:
  k8s_cluster:
    allocatable_types_to_report:
      - cpu
      - memory
      - ephemeral-storage
      - storage
      - pods
    auth_type: serviceAccount
    collection_interval: 30s
    # use distribution as openshift if deployed to redhat openshift
    distribution: kubernetes
    metrics:
      k8s.container.cpu_request:
        enabled: true
      k8s.container.memory_request:
        enabled: true
      k8s.node.condition:
        enabled: true
    node_conditions_to_report:
      - Ready
      - DiskPressure
      - MemoryPressure
      - PIDPressure
      - NetworkUnavailable
  k8s_events:
    auth_type: serviceAccount
  k8sobjects/1:
    auth_type: serviceAccount
    objects:
      - interval: 24h
        mode: pull
        name: pods
      - interval: 24h
        mode: pull
        name: nodes
      - mode: pull
        name: replicasets
      - mode: pull
        name: namespaces
      - mode: pull
        name: deployments
      - mode: pull
        name: daemonsets
      - mode: pull
        name: statefulsets
      - mode: pull
        name: configmaps
  k8sobjects/2:
    auth_type: serviceAccount
    objects:
      - mode: watch
        name: pods
      - mode: watch
        name: nodes
      - mode: watch
        name: replicasets
      - mode: watch
        name: namespaces
      - mode: watch
        name: deployments
      - mode: watch
        name: daemonsets
      - mode: watch
        name: statefulsets
      - mode: watch
        name: configmaps
  otlp:
    protocols:
      grpc:
        endpoint: "0.0.0.0:4317"
      http:
        endpoint: "0.0.0.0:4318"
service:
  extensions:
    - health_check
  pipelines:
    logs/k8s_events:
      exporters:
        - otlphttp
      processors:
        - resource/k8s_events
        - resource
        - resource/cluster
        - k8sattributes
        - transform/loglevels
        - batch
      receivers:
        - k8s_events
    logs/k8sobjects:
      exporters:
        - otlphttp
      processors:
        - resource
        - resource/k8s_objects
        - resource/cluster
        - k8sattributes
        - batch
      receivers:
        - k8sobjects/1
        - k8sobjects/2
    logs/otlp:
      exporters:
        - otlphttp
      processors:
        - resource
        - resource/cluster
        - k8sattributes
        - transform/copyservicefromlogattributes
        - batch
      receivers:
        - otlp
    metrics/k8s_cluster:
      exporters:
        - otlphttp
      processors:
        - resource
        - k8sattributes
        - resource/cluster
        - batch
      receivers:
        - k8s_cluster
    metrics/otlp:
      exporters:
        - otlphttp
      processors:
        - resource
        - k8sattributes
        - resource/cluster
        - batch
      receivers:
        - otlp
    traces/otlp:
      exporters:
        - otlphttp
      processors:
        - resource
        - resource/cluster
        - k8sattributes
        - batch
      receivers:
        - otlp